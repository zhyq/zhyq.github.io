<h1 id="搜索扩招回之query-改写">搜索扩招回之query 改写</h1>
<h4 id="背景">背景</h4>
<p>召回和排序是搜索的两个重要模块。召回的功能就是根据用户的query，尽可能的找出更多query相关的结果。query改写(query rewrite )是query扩召回的重要组成部分。通过对原始query进行改写，扩展出多个相关query，作为原始query的补充，与原始query一起参与搜索，从而返回更加丰富和准确的搜索结果</p>
<h4 id="query-rewrite-的方法">query rewrite 的方法</h4>
<p>query rewrite方法很多， 关键在于理解业务场景，构造合理的特征。</p>
<ul>
<li>1 基于日志挖掘的方法 基于用户的行为数据，挖掘query和query之间的关系。 query点击日志和query session日志是比较容易想到的数据。对于点击同一文档的query建立query共现关系，以及基于同一个session下的query建立共现关系。 点击日志和session日志的数据各有优缺点，session 的数据不过度依赖搜索结果。点击的数据普适性更强。可以结合使用</li>
<li>基于session的优点是不依赖现有的搜索结果。如果用户搜q1搜不到结果，可以继续搜q2，发现了想要的。如此，q1和q2就建立了联系。以后用户搜q1，就可以把q2的结果返回回来。和session数据相比，点击的数据 缺点就是依赖现有的搜索返回的结果。如果搜索q1在现有搜索引擎下召不回任何结果，q1就没法和其他任何的query建立联系</li>
<li>点击的数据是多个不同用户搜索不同query点击的同一文档的数据。把不同用户之间的搜素建立关系。往往泛化能力更强。session数据建立的是个体内部的query关系。存在知识偏差。 举个例子：之前的一部电影叫做 &quot;西虹市首富&quot; ,大部分用户以为电影名为&quot;西红柿首富&quot;，很少有用户会先搜&quot;西红柿首富&quot;，再搜&quot;西虹市首富&quot;。session中 共线关系很强的都是 西红首富 西红柿 首富 等词，基于session很难挖掘到 &quot;西红柿首富&quot;扩展到&quot;西虹市首富&quot;。 而点击就会弱化这个关系，用户X搜索 &quot;西虹市首富&quot;点击了西虹市首富电影相关的doc，用户Y搜索&quot;西红柿首富&quot;，通过翻了很多页也点击了这个doc,基于点击的数据就能更容易的挖掘到 &quot;西红柿首富&quot;扩展到&quot;西虹市首富&quot; 基于挖掘的效果如下：</li>
</ul>
<p>```js</p>
<pre><code> 小艾姑娘    小爱姑娘
 冬瓜动漫    冬瓜漫画
 断桥姑娘公众号  断桥姑娘
 英语46级    四级英语
 中国邮政快递单号查询    中国邮政
 阿拉蕾表情  阿拉蕾的表情包
 毛线拖鞋编织    毛线编织
 清马    清远马拉松
 圣诞节招募  圣诞节活动招募
 关牧村歌曲  关牧村歌曲大全
 tfbays  tfboys
 中国水利网  中国水利
 美女情趣    美女小视频
 卫生    卫生巾</code></pre>
<p>```</p>
<p>基于挖掘的算法计算简单，能够快速更新数据，数据量足够大的情况下，效果也基本够用。缺点是需要大量的日志，而且简单粗暴，不能挖掘更深层次的关系，对于低频query效果不是很好。</p>
<ul>
<li><p>2 基于知识体系替换，通过query中词的同义词、上下位词替换改写query.</p>
<div class="sourceCode"><pre class="sourceCode js"><code class="sourceCode javascript">
  苹果6手机多少钱 <span class="op">-&gt;</span> iphone6多少钱 
  新鲜水果<span class="op">-&gt;</span>新鲜苹果 </code></pre></div></li>
</ul>
<p>上下位词关系一般牵涉到知识图谱挖掘，有兴趣可以去网上看看知识图谱的相关知识，这里不做过多介绍。 同义词挖掘方法很多，有语料对齐挖掘，上下文挖掘等 语料对齐法：可以拿点击日志、session日志、anchor语料 通过上述1.1方法挖掘到对齐语料。再使用机器翻译模型(比如 IBM Model1)等从对齐语料中挖掘同义词。 上下文挖掘：简单来说就是同义词往往有着相似的上下文。通过计算词的上下文相似程度来挖掘同义词</p>
<p>```js</p>
<pre><code>   折抵换购 iPhone XR 仅 RMB 176/月起  
   折抵换购 苹果 XR 仅 RMB 176/月起</code></pre>
<p>```</p>
<p>挖掘的同义词效果如下：</p>
<pre><code>```js

   面包机  厨师机
   尿布湿  尿片
   醒酒    解酒
   工行    icbc
   握力圈  握力器
   运费    邮费
   美人图  美女照片
   车厘子  樱桃
   创口贴  创可贴
   ems 邮政速递
   文胸    bra
   文胸  内衣
   文胸 胸罩
```</code></pre>
<ul>
<li>3 基于深度学习的方法 基于深度学习方法做query rewrite的方法很多。这里讲解一些笔者用到方法</li>
<li><p>3.1 基于上下文的query2vec 和word2vec doc2vec原理一样，利用语言模型的原理，上下文相关的query具有相似性。将共现的query看做句子。比如将用一个session的所有query 或者点击同一个doc的所有query 看做句子。把query看做token,训练 query向量。详细方法可参照<a href="https://astro.temple.edu/~tuc17157/pdfs/grbovic2015sigir.pdf">相关论文</a> 效果如下：</p>
<p>```js</p>
<p>使用query2vec算出历史query的embedding,再通过聚类方法，把query聚合成多个簇， 同一个簇对应的query可以作为其中一个query的扩展 query 聚簇id ------------- 京东白条 39 京东金融服务 39 京东好借 39 京东金条公众号 39 京东金条贷 39 京东金融一站通 39 京东支付 39 设计 40 ps 40 h5 40 海报 40 工商银行信用卡 41 工商银行信用卡中心 41 韵达快递 42 韵达 42 韵达快递查询 42 韵达快递单号查询 42 韵达快递公众号 42 韵达速递 42 视频去水印 43 抖音去水印小工具 43 ```</p></li>
</ul>
<p>   * 3.2 deepwalk     deepwalk和3.1类似，区别在构造sentence上下文采用随机游走的方法。 随机游走的原理：将query之间的关系建立成图。通过从一个点随机游走，建立起多条条路径，每条路径上的query组成一个句子。再使用上下文相关原理(3.1)训练query的embedding. 随机游走的优点就是关系具有传递性，和query共现不同,可以将间接关系的query建立联系。少量的数据经过游走能够产生够多的训练数据。例如session1:q1-&gt;q2 session2:q2-&gt;q3. 共线的方法无法直接建立q1-&gt;q3的关系。而随机游走能够很好的解决。 deepwalk 效果如下：</p>
<pre><code>  ```js

   使用deepwalk 算出query的embedding,
   再根据每个queryembedding，去找相近的query,作为此query的扩展。
   下面是 物流 这个词 通过embedding 算cosine 找出的相关query
   相关query  Cosine distance
   --------------------------
   联邦物流    0.989296
   物流投诉    0.987607
   邮政平邮查询    0.987414
   发物流    0.987017
   物流网    0.986942
   路路通物流    0.986601
   物流快领券    0.985996
   春节发货    0.985922
   银杯    0.985884
   哈尔滨物流    0.985803
   金山物流    0.985749
   海运物流    0.985740
   顺丰物流查询    0.985537
  ```</code></pre>
<ul>
<li><p>3.3 bert 关于bert模型的基本原理，读者有兴趣可以去网上搜索。简单的说，就是输入sententce，采用transformer+mask方法，tonken(单字)embedding 作为输入的基本特征，训练出 sentence的向量并输出。后续可以采用Fine-tuning方法，再在外面将sentence 的embedding 和 label 数据 套上loss目标函数，完成对具体任务的训练。 笔者将数据构造成 q1 q2 label的方式。训练样本的构造可按参照上面挖掘的方法，把挖到的数据做正样本，随机的query 对为负样本。 将q1 ， q2作为输入，得到sentence embedding，再根据label来计算loss，这样就可以学习到 q1和q2的相似性。 具体参考bert中run_classifier.py的squad例子。</p>
<div class="sourceCode"><pre class="sourceCode js"><code class="sourceCode javascript">
   苹果 iphone <span class="dv">1</span>
   苹果 电脑 <span class="dv">0</span></code></pre></div></li>
</ul>
